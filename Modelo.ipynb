{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f202707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTAMOS LAS LIBRERIAS BASADAS EN TENSORFLOW Y KERAS\n",
    "import sys\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.keras.layers import  Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bd164fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIMPIAMOS SESION DE KERAS PARA EMPEZAR DESDE 0 EN MEMORIA\n",
    "K.clear_session()\n",
    "#GENERAMOS 2 VARIABLES CON CADA UNA DE LAS CARPETAS TANTO DE ENTRENAMIENTO COMO DE TEST CON FOTOGRAFIAS\n",
    "data_entrenamiento = './CarneDataset/train'\n",
    "data_validacion = './CarneDataset/test'\n",
    "#DECLARACION DE VARIABLES CON VALORES QUE PARAMETRIZARAN EL DESEMPEÑO DEL ENTRENAMIENTO DEL MODELO DE CLASIFICACION DE FOTOS\n",
    "epocas=15 #NUMERO DE EPOCHS PARA EL TRAINING\n",
    "longitud, altura = 100, 100 #REDIMENSIONAMIENTO DE FOTOGRAFIAS\n",
    "batch_size = 10 # TAMAÑO DE FOTOGRAFIAS A GESTIONAR\n",
    "pasos = 120 #NUMERO DE STEPS PARA ENTRENAMIENTO\n",
    "validation_steps = 80 #NUMERO DE STEPS PARA VALIDACION\n",
    "clases = 8 #CANTIDAD DE CLASES DE FOTOGRAFIAS A CLASIFICAR\n",
    "lr = 0.001 #LERANING RATE PARA EL PROCESO DE ENTRENAMIENTO\n",
    "# Declaracion de variables con valores para el modelo\n",
    "filtrosConv1 = 32\n",
    "filtrosConv2 = 64\n",
    "tamano_filtro1 = (3, 3)\n",
    "tamano_filtro2 = (2, 2)\n",
    "tamano_pool = (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c729a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1634 images belonging to 8 classes.\n",
      "Found 810 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "#FUNCION IMAGEDATAGENERATOR QUE PROPORCIONARA MODIFICACION A FOTOGRAFIAS PARA OPTIMIZAR EL PROCESO DE ENTRENAMIENTO\n",
    "entrenamiento_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,  # Rango de rotación aleatoria en grados\n",
    "    width_shift_range=0.1,  # Rango de desplazamiento horizontal aleatorio\n",
    "    height_shift_range=0.1,  # Rango de desplazamiento vertical aleatorio\n",
    "    rescale=1. / 255, # Rango de escala de la imagen\n",
    "    shear_range=0.2, # Rango de efecto de inclinación o distorsión\n",
    "    zoom_range=0.2, # Rango de efecto de zoom\n",
    "    horizontal_flip=True) # aplicar volteo horizontal a las imágenes\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "#FUNCION PARA CONFIGURACION DEL PROCESO DE RECUPERACION DE INFORMACION DE FOTOS PARA ENTRENAMIENTO\n",
    "entrenamiento_generador = entrenamiento_datagen.flow_from_directory(\n",
    "    data_entrenamiento,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "#FUNCION PARA CONFIGURACION DEL PROCESO DE RECUPERACION DE INFORMACION DE FOTOS PARA TEST\n",
    "validacion_generador = test_datagen.flow_from_directory(\n",
    "    data_validacion,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc28601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCION PARA EMPEZAR EL MODELO Y SU CONSTRUCCION\n",
    "cnn = Sequential()\n",
    "#PRIMERA CAPA\n",
    "cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding =\"same\", input_shape=(longitud, altura, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "#SEGUNDA CAPA\n",
    "cnn.add(Convolution2D(filtrosConv2, tamano_filtro2, padding =\"same\", activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "#RECONFIGURACION DE LA INFORMACION EN DATOS RECONOCIBLES POR EL MODELO\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(256, activation='relu'))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(clases, activation='softmax'))\n",
    "#COMPILACION DE LA INFORMACION DENTRO DEL MODELO PARA SU ENTRENAMIENTO \n",
    "cnn.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizers.Adam(learning_rate=lr),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "513de80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "# Definir una función para reducir el learning rate gradualmente\n",
    "def lr_scheduler(epoch):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.1\n",
    "\n",
    "# Crear un objeto LearningRateScheduler\n",
    "lr_scheduler_callback = LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34bb2b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "120/120 [==============================] - 46s 368ms/step - loss: 1.4860 - accuracy: 0.5595 - val_loss: 1.1850 - val_accuracy: 0.6463 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 44s 364ms/step - loss: 1.0081 - accuracy: 0.6450 - val_loss: 0.7328 - val_accuracy: 0.7225 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 44s 368ms/step - loss: 0.8638 - accuracy: 0.6817 - val_loss: 0.7363 - val_accuracy: 0.7538 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 44s 366ms/step - loss: 0.7167 - accuracy: 0.7286 - val_loss: 1.1120 - val_accuracy: 0.5975 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 44s 364ms/step - loss: 0.6295 - accuracy: 0.7672 - val_loss: 1.0167 - val_accuracy: 0.6087 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 45s 375ms/step - loss: 0.6485 - accuracy: 0.7533 - val_loss: 0.8630 - val_accuracy: 0.6550 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 44s 369ms/step - loss: 0.5623 - accuracy: 0.7915 - val_loss: 0.5810 - val_accuracy: 0.7788 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 43s 362ms/step - loss: 0.5782 - accuracy: 0.7764 - val_loss: 0.7970 - val_accuracy: 0.6750 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 44s 368ms/step - loss: 0.5049 - accuracy: 0.8117 - val_loss: 0.5351 - val_accuracy: 0.8075 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 44s 370ms/step - loss: 0.4878 - accuracy: 0.8116 - val_loss: 0.4118 - val_accuracy: 0.8487 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 44s 365ms/step - loss: 0.3881 - accuracy: 0.8559 - val_loss: 0.7180 - val_accuracy: 0.7237 - lr: 1.0000e-04\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 44s 364ms/step - loss: 0.3486 - accuracy: 0.8668 - val_loss: 0.6247 - val_accuracy: 0.7638 - lr: 1.0000e-04\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 44s 362ms/step - loss: 0.3402 - accuracy: 0.8610 - val_loss: 0.5757 - val_accuracy: 0.7800 - lr: 1.0000e-04\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 44s 364ms/step - loss: 0.3553 - accuracy: 0.8769 - val_loss: 0.7252 - val_accuracy: 0.7337 - lr: 1.0000e-04\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 44s 365ms/step - loss: 0.3049 - accuracy: 0.8861 - val_loss: 0.7743 - val_accuracy: 0.7337 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "#ENTRENAMIENTO DEL MODELO SEGUN LOS DATOS INGRESADOS COMO PARAMETROS\n",
    "historia = cnn.fit(\n",
    "    entrenamiento_generador,\n",
    "    steps_per_epoch=pasos,\n",
    "    epochs=epocas,\n",
    "    validation_data=validacion_generador,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[lr_scheduler_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93f181e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "Loss: 0.30\n",
      "Validation Accuracy: 0.73\n",
      "Validation Loss: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el accuracy y la loss\n",
    "acc = historia.history['accuracy']\n",
    "loss = historia.history['loss']\n",
    "val_acc = historia.history['val_accuracy']\n",
    "val_loss = historia.history['val_loss']\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Accuracy: {acc[-1]:.2f}\")\n",
    "print(f\"Loss: {loss[-1]:.2f}\")\n",
    "print(f\"Validation Accuracy: {val_acc[-1]:.2f}\")\n",
    "print(f\"Validation Loss: {val_loss[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "406e2057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREACION Y ALMACENAMIENTO DEL RESULTANTE DEL ENTRENAMIENTO PARA RECONOCIMIENTO DE FOTOGRAFIAS\n",
    "target_dir = './modelo/'\n",
    "if not os.path.exists(target_dir):\n",
    "  os.mkdir(target_dir)\n",
    "cnn.save('./modelo/modelo.h5')\n",
    "cnn.save_weights('./modelo/pesos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b9066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
